{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S08JEIKD1D4",
        "outputId": "fa8c0dc4-365d-4adb-81a1-5c8bb0906802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94mcode\u001b[39m E404\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94m404\u001b[39m Not Found - GET https://registry.npmjs.org/localtunne - Not found\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94m404\u001b[39m\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94m404\u001b[39m  'localtunne@*' is not in this registry.\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94m404\u001b[39m\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94m404\u001b[39m Note that you can also install from a\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94m404\u001b[39m tarball, folder, http url, or git url.\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m A complete log of this run can be found in: /root/.npm/_logs/2025-08-01T12_00_36_414Z-debug-0.log\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit\n",
        "!npm install -q localtunne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkGH989cGT42",
        "outputId": "557fa570-e995-4f98-f72d-6703a866ba7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import streamlit as st\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             roc_auc_score, confusion_matrix, roc_curve)\n",
        "import joblib\n",
        "\n",
        "# ------------------- Data Loading -------------------\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    df = pd.read_csv(\"Employee-Attrition - Employee-Attrition.csv\")\n",
        "    df = df.drop(['EmployeeCount', 'Over18', 'StandardHours', 'EmployeeNumber'], axis=1)\n",
        "    df['AttritionFlag'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "    df.drop('Attrition', axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# ------------------- Task Selection -------------------\n",
        "st.title(\"Employee Insights & Prediction Dashboard\")\n",
        "task = st.sidebar.selectbox(\"Select Prediction Task\", [\n",
        "    \"Attrition Prediction\",\n",
        "    \"Promotion Likelihood Prediction\"\n",
        "])\n",
        "\n",
        "# ------------------- Task-specific Feature Selection -------------------\n",
        "if task == \"Attrition Prediction\":\n",
        "    target = \"AttritionFlag\"\n",
        "    features = [\"Age\", \"Department\", \"MonthlyIncome\", \"JobSatisfaction\",\n",
        "                \"YearsAtCompany\", \"MaritalStatus\", \"OverTime\"]\n",
        "    model_type = \"classification\"\n",
        "    st.header(\"Attrition Prediction\")\n",
        "\n",
        "elif task == \"Promotion Likelihood Prediction\":\n",
        "    target = \"YearsSinceLastPromotion\"\n",
        "    features = [\"JobLevel\", \"TotalWorkingYears\", \"YearsInCurrentRole\",\n",
        "                \"PerformanceRating\", \"Education\"]\n",
        "    model_type = \"regression\"\n",
        "    st.header(\"Promotion Likelihood Prediction\")\n",
        "\n",
        "# ------------------- EDA -------------------\n",
        "st.subheader(\"Exploratory Data Analysis (EDA)\")\n",
        "# Histogram\n",
        "st.markdown(\"### Histograms\")\n",
        "numeric_cols = df[features].select_dtypes(include=['int64', 'float64']).columns\n",
        "for col in numeric_cols:\n",
        "    fig, ax = plt.subplots()\n",
        "    sns.histplot(data=df, x=col, kde=True, ax=ax)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# Countplots for categorical\n",
        "st.markdown(\"### Categorical Distributions\")\n",
        "cat_cols = df[features].select_dtypes(include='object').columns\n",
        "for col in cat_cols:\n",
        "    fig, ax = plt.subplots()\n",
        "    sns.countplot(data=df, x=col, ax=ax)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# Correlation heatmap\n",
        "st.markdown(\"### Correlation Heatmap\")\n",
        "numeric_df = df.select_dtypes(include=np.number)\n",
        "corr = numeric_df.corr()\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=ax)\n",
        "ax.set_title(\"Correlation Heatmap\")\n",
        "st.pyplot(fig)\n",
        "\n",
        "# ------------------- Preprocessing -------------------\n",
        "df_model = df[features + [target]].copy()\n",
        "df_model = pd.get_dummies(df_model, drop_first=True)\n",
        "\n",
        "X = df_model.drop(target, axis=1)\n",
        "y = df_model[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ------------------- Model Training -------------------\n",
        "if model_type == \"classification\":\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "        \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
        "        \"SVM\": SVC(kernel='rbf', probability=True),\n",
        "        \"Decision Tree\": DecisionTreeClassifier()\n",
        "    }\n",
        "else:\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    from sklearn.tree import DecisionTreeRegressor\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "    models = {\n",
        "        \"Linear Regression\": LinearRegression(),\n",
        "        \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100),\n",
        "        \"Decision Tree Regressor\": DecisionTreeRegressor()\n",
        "    }\n",
        "\n",
        "metrics = []\n",
        "roc_data = {}\n",
        "conf_matrices = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    if model_type == \"classification\":\n",
        "        y_prob = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, \"predict_proba\") else y_pred\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        prec = precision_score(y_test, y_pred, average='macro')\n",
        "        rec = recall_score(y_test, y_pred, average='macro')\n",
        "        f1 = f1_score(y_test, y_pred, average='macro')\n",
        "        auc = roc_auc_score(y_test, y_prob, multi_class='ovr') if len(np.unique(y)) > 2 else roc_auc_score(y_test, y_prob)\n",
        "        metrics.append([name, acc, prec, rec, f1, auc])\n",
        "        if len(np.unique(y)) == 2:\n",
        "            fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "            roc_data[name] = (fpr, tpr)\n",
        "        conf_matrices[name] = confusion_matrix(y_test, y_pred)\n",
        "    else:\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        metrics.append([name, mse, mae, r2])\n",
        "\n",
        "# ------------------- Evaluation -------------------\n",
        "st.subheader(\"Model Evaluation Metrics\")\n",
        "if model_type == \"classification\":\n",
        "    metrics_df = pd.DataFrame(metrics, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"AUC-ROC\"])\n",
        "else:\n",
        "    metrics_df = pd.DataFrame(metrics, columns=[\"Model\", \"MSE\", \"MAE\", \"R2\"])\n",
        "st.dataframe(metrics_df.set_index(\"Model\"))\n",
        "\n",
        "if model_type == \"classification\":\n",
        "    st.subheader(\"Confusion Matrices\")\n",
        "    for model_name, cm in conf_matrices.items():\n",
        "        st.write(f\"**{model_name}**\")\n",
        "        fig, ax = plt.subplots()\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
        "        ax.set_xlabel(\"Predicted\")\n",
        "        ax.set_ylabel(\"Actual\")\n",
        "        st.pyplot(fig)\n",
        "\n",
        "    if len(np.unique(y)) == 2:\n",
        "        st.subheader(\"ROC Curves\")\n",
        "        fig, ax = plt.subplots()\n",
        "        for model_name, (fpr, tpr) in roc_data.items():\n",
        "            ax.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc_score(y_test, models[model_name].predict_proba(X_test_scaled)[:,1]):.2f})\")\n",
        "        ax.plot([0, 1], [0, 1], linestyle='--')\n",
        "        ax.set_xlabel(\"False Positive Rate\")\n",
        "        ax.set_ylabel(\"True Positive Rate\")\n",
        "        ax.legend()\n",
        "        st.pyplot(fig)\n",
        "\n",
        "# ------------------- Feature Importance -------------------\n",
        "if \"Random Forest\" in models or \"Random Forest Regressor\" in models:\n",
        "    st.subheader(\"Feature Importance (Random Forest)\")\n",
        "    rf_key = \"Random Forest\" if \"Random Forest\" in models else \"Random Forest Regressor\"\n",
        "    rf_model = models[rf_key]\n",
        "    if hasattr(rf_model, \"feature_importances_\"):\n",
        "        importances = rf_model.feature_importances_\n",
        "        indices = np.argsort(importances)[::-1]\n",
        "        top_features = X.columns[indices[:15]]\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        sns.barplot(x=importances[indices[:15]], y=top_features, ax=ax)\n",
        "        ax.set_title(\"Top 15 Important Features\")\n",
        "        st.pyplot(fig)\n",
        "\n",
        "# ------------------- Hyperparameter Tuning -------------------\n",
        "st.subheader(\"Hyperparameter Tuning: Random Forest\")\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "rf_class = RandomForestClassifier if model_type == \"classification\" else RandomForestRegressor\n",
        "grid = GridSearchCV(rf_class(random_state=42), param_grid, cv=3, scoring='f1_macro' if model_type == \"classification\" else 'r2')\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "st.write(\"Best Parameters:\", grid.best_params_)\n",
        "st.write(\"Best Score:\", grid.best_score_)\n",
        "\n",
        "# ------------------- Save Best Model -------------------\n",
        "best_model = max(metrics, key=lambda x: x[-1])\n",
        "joblib.dump(models[best_model[0]], f\"best_model_{task.replace(' ', '_')}_{best_model[0].replace(' ', '_')}.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWTLvbrmGijj",
        "outputId": "95ec2701-a7a2-4fad-afee-81b39c6a37f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0Kyour url is: https://social-toys-shop.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. EDA (Exploratory Data Analysis)\n",
        "Histograms for numerical features\n",
        "\n",
        "Countplots for categorical features\n",
        "\n",
        "Correlation heatmap\n",
        "\n",
        " 2. Prediction Tasks\n",
        "Attrition Prediction (classification)\n",
        "\n",
        "Logistic Regression, SVM, Decision Tree, Random Forest\n",
        "\n",
        "Promotion Likelihood Prediction (regression)\n",
        "\n",
        "Linear Regression, Decision Tree Regressor, Random Forest Regressor\n",
        "\n",
        "3. Model Evaluation\n",
        "Classification: Accuracy, Precision, Recall, F1-score, AUC-ROC, Confusion Matrix, ROC Curve\n",
        "\n",
        "Regression: MSE, MAE, R² Score\n",
        "\n",
        "4. Feature Importance\n",
        "Top 15 features by importance (Random Forest)\n",
        "\n",
        "5. Hyperparameter Tuning\n",
        "GridSearchCV on Random Forest\n",
        "\n",
        "Displays best parameters and cross-validation score\n",
        "\n",
        " 6. Model Saving\n",
        "Automatically saves the best-performing model based on F1-score or R²."
      ],
      "metadata": {
        "id": "RWTeTBbbgGen"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MZWmLrDygGSY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}